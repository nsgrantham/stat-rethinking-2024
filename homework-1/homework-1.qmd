---
title: Statistical Rethinking 2024, Week 1
author: Neal Grantham
date: 2024-01-12
---

```{julia}
# Julia v1.9.3
using StatsBase
using StatsPlots
using Distributions
using Turing
```

```{julia}
#| echo: false
import Random
Random.seed!(777)  # for reproducibility

import Logging
Logging.disable_logging(Logging.Warn)  # hide "Sampling" messages from Turing

# Plot defaults
default(c=:grey70, bar_width=0.5, guidefontfamily="Inter-Regular", legend=false)
```

Q1. Suppose the globe tossing data (Lecture 2, Chapter 2) had turned out to be 3 water and 11 land.
Construct the posterior distribution.

```{julia}
@model function globetoss1(w, l)
    n = w + l
    p ~ Beta(1, 1)
    w ~ Binomial(n, p)
end

model = globetoss1(3, 11)
chain = sample(model, NUTS(), 10_000)

density(chain[:p], xlims=(0, 1), ylab="posterior density", xlab="proportion water")
```

Q2. Using the posterior distribution from Q1, compute the posterior predictive distribution for the next 5 tosses of the same globe.
I recommend you use the sampling method.

```{julia}
pred_post = rand.(Binomial.(5, chain[:p]))

bar(countmap(pred_post), ylab="count", xlab="number of water")
```

Q3. Suppose you observe $W = 7$ water points, but you forgot to write down how many times the globe was tossed, so you don't know the number of land points $L$.
Assume that $p = 0.7$ and compute the posterior distribution of tosses $N$.
Hint: Use the binomial distribution.

```{julia}
@model function globetoss2(w, p)
    n ~ Poisson(w / p)
    w ~ Binomial(n, p)
end

model = globetoss2(7, 0.7)
chain = sample(model, MH(), 10_000)

bar(
    proportionmap(chain[:n]), xticks=7:30,
    ylab="posterior probability", xlab="number of tosses"
)
```
